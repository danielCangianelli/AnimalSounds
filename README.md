# ğŸ¾ Animal Sound Classifier

## Projeto completo de classificaÃ§Ã£o de sons de animais baseado em Machine Learning. Composto por:

ğŸ“Š Processamento de dados e preparaÃ§Ã£o de dataset (ESC-50);

ğŸ§  Treinamento do modelo via Create ML e [TensorFlow];

ğŸ“± Aplicativo iOS desenvolvido em SwiftUI + MVVM, com uso de microfone e modelo embarcado;

ğŸ§ª ExportaÃ§Ã£o e uso do modelo em Python para testes automatizados.

## ğŸ“ Estrutura do Projeto

```plaintext
AnimalSoundClassifier/
â”‚
â”œâ”€â”€ data/                    # CSV original e Ã¡udios do ESC-50
â”œâ”€â”€ training_data/           # Dados de treino organizados por classe
â”œâ”€â”€ testing_data/            # Dados de teste organizados por classe
â”œâ”€â”€ notebooks/               # Notebooks de EDA, prÃ©-processamento e avaliaÃ§Ã£o
â”œâ”€â”€ model/                   # Modelo treinado (.h5) + encoder (.pkl)
â”œâ”€â”€ ios-app/                 # App iOS SwiftUI usando CoreML
â”œâ”€â”€ export/                  # ExportaÃ§Ãµes (.h5, .pkl)
â”œâ”€â”€ predict.py               # Script de prediÃ§Ã£o em Python
â”œâ”€â”€ export_model.py          # Script de exportaÃ§Ã£o de modelo e encoder
â”œâ”€â”€ esc50.csv                # CSV oficial com metadados
â”œâ”€â”€ README.md
```

### ğŸ“† Dataset

Utiliza o *ESC-50*: Dataset for Environmental Sound Classification, filtrando 5 classes:

`dog`, `cat`, `cow`, `rooster`, `sheep`

##  ğŸ›  Fluxo de Processamento

### 1. PreparaÃ§Ã£o dos Dados

Executado em Jupyter Notebook com pandas, scikit-learn, librosa, etc.

selected_classes = ['dog', 'cat', 'cow', 'rooster', 'sheep']
test_set_size = 0.20

Filtragem das classes de interesse

DivisÃ£o entre treino e teste com train_test_split

OrganizaÃ§Ã£o em diretÃ³rios separados por classe

### 2. Treinamento do Modelo

ğŸ”¹ OpÃ§Ã£o A: Create ML

Projeto Sound Classifier

ConfiguraÃ§Ã£o:

Window Duration: 1.0s

Overlap: 0.5s

Exportado como .mlmodel e utilizado diretamente no app iOS

ğŸ”¹ OpÃ§Ã£o B: TensorFlow (Python)

model = Sequential([
    Dense(256, activation='relu', input_shape=(40,)),
    Dropout(0.3),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(num_classes, activation='softmax')
])

ExtraÃ§Ã£o de features com librosa (MFCC)

AcurÃ¡cia final: ~70%

ExportaÃ§Ã£o:

model.save('export/animal_sounds_model.h5')
with open('export/label_encoder.pkl', 'wb') as f:
    pickle.dump(encoder, f)

### 3. Testes em Python

Uso de predict.py para testar o modelo com novos .wav:

python predict.py caminho/do/arquivo.wav

PrÃ©-processamento com MFCC

DecodificaÃ§Ã£o da classe com LabelEncoder

### 4. App iOS com SwiftUI

Desenvolvido em SwiftUI + MVVM

Usa o microfone do dispositivo e o modelo .mlmodel

PermissÃµes configuradas no Info.plist (ou via Swift para projetos sem plist)

ğŸ” PermissÃµes

NSMicrophoneUsageDescription = "Este app precisa acessar o microfone para identificar sons de animais."

ğŸ” VerificaÃ§Ã£o de permissÃ£o

switch AVAudioSession.sharedInstance().recordPermission {
case .undetermined:
    AVAudioSession.sharedInstance().requestRecordPermission { granted in ... }
case .denied:
    // Informar o usuÃ¡rio
case .granted:
    // Continuar normalmente
}

ğŸ“¦ Requisitos

Python

pip install pandas librosa scikit-learn tensorflow matplotlib

iOS

Xcode 15+

Swift 6

Target: iOS 16+

ğŸ§  Autor

- **DuckNCode** - *Desenvolvedor principal* - [@dCangianelli](https://github.com/danielCangianelli)
